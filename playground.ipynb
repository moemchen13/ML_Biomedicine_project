{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from streamlit_timeline import timeline\n",
    "import json\n",
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "from streamlit_pandas_profiling import st_profile_report\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>79.53</td>\n",
       "      <td>31.1</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>78.44</td>\n",
       "      <td>23.9</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>103.00</td>\n",
       "      <td>40.3</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>64.87</td>\n",
       "      <td>28.8</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>73.36</td>\n",
       "      <td>28.8</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15299</th>\n",
       "      <td>Female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Govt_job</td>\n",
       "      <td>Urban</td>\n",
       "      <td>72.63</td>\n",
       "      <td>19.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15300</th>\n",
       "      <td>Female</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>101.19</td>\n",
       "      <td>32.1</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15301</th>\n",
       "      <td>Female</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Urban</td>\n",
       "      <td>87.69</td>\n",
       "      <td>26.2</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15302</th>\n",
       "      <td>Male</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>101.13</td>\n",
       "      <td>22.5</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15303</th>\n",
       "      <td>Female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>85.12</td>\n",
       "      <td>24.7</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15304 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender   age  hypertension  heart_disease ever_married      work_type  \\\n",
       "id                                                                             \n",
       "0        Male  28.0             0              0          Yes        Private   \n",
       "1        Male  33.0             0              0          Yes        Private   \n",
       "2      Female  42.0             0              0          Yes        Private   \n",
       "3        Male  56.0             0              0          Yes        Private   \n",
       "4      Female  24.0             0              0           No        Private   \n",
       "...       ...   ...           ...            ...          ...            ...   \n",
       "15299  Female  22.0             0              0           No       Govt_job   \n",
       "15300  Female  46.0             1              0          Yes        Private   \n",
       "15301  Female  75.0             0              0          Yes  Self-employed   \n",
       "15302    Male  46.0             0              0          Yes        Private   \n",
       "15303  Female  14.0             0              0           No        Private   \n",
       "\n",
       "      Residence_type  avg_glucose_level   bmi   smoking_status  stroke  \n",
       "id                                                                      \n",
       "0              Urban              79.53  31.1     never smoked       0  \n",
       "1              Rural              78.44  23.9  formerly smoked       0  \n",
       "2              Rural             103.00  40.3          Unknown       0  \n",
       "3              Urban              64.87  28.8     never smoked       0  \n",
       "4              Rural              73.36  28.8     never smoked       0  \n",
       "...              ...                ...   ...              ...     ...  \n",
       "15299          Urban              72.63  19.5     never smoked       0  \n",
       "15300          Urban             101.19  32.1     never smoked       0  \n",
       "15301          Urban              87.69  26.2     never smoked       0  \n",
       "15302          Rural             101.13  22.5          Unknown       0  \n",
       "15303          Rural              85.12  24.7     never smoked       0  \n",
       "\n",
       "[15304 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('stroke.csv', index_col=0)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select machine lernning model\n",
    "def select_model(model):\n",
    "    if model==\"Logistic Regression\":\n",
    "        metric = accuracy_score\n",
    "        ML_model = LogisticRegression()\n",
    "    elif model == \"Decision Tree\":\n",
    "        metric = accuracy_score\n",
    "        ML_model = tree.DecisionTreeClassifier()\n",
    "    elif model == \"Random Forest\":\n",
    "        metric = accuracy_score\n",
    "        ML_model = RandomForestClassifier()\n",
    "    elif model == \"Linear Regression\":\n",
    "        metric = mean_squared_error\n",
    "        ML_model = LinearRegression()\n",
    "    elif model == \"Regression Tree\":\n",
    "        metric = mean_squared_error\n",
    "        ML_model = tree.DecisionTreeRegressor()\n",
    "    elif model == \"Ridge Regression\":\n",
    "        metric = mean_squared_error\n",
    "        ML_model = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom imputation using random values between min and max for each column\n",
    "def random_impute(X):\n",
    "    for i in range(X.shape[1]):\n",
    "        col = X[:, i]\n",
    "        missing = np.isnan(col)\n",
    "        col_min, col_max = np.nanmin(col), np.nanmax(col)\n",
    "        col[missing] = np.random.uniform(col_min, col_max, size=missing.sum())\n",
    "    return X\n",
    "        \n",
    "def clean_data(X, imputation_strategy='most_frequent', scaling_method='minmax'):\n",
    "    # Separate numerical and non-numerical columns\n",
    "    numerical_cols = X.select_dtypes(include=[np.number]).columns\n",
    "    categorical_cols = X.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "    # Handle missing values based on the chosen imputation strategy\n",
    "    if imputation_strategy in ['mean', 'median','most_frequent']:\n",
    "        imputer = SimpleImputer(strategy=imputation_strategy)\n",
    "        X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "    elif imputation_strategy == 'random':        \n",
    "        X_imputed = random_impute(X.copy())  # Apply random imputation before scaling\n",
    "    else:\n",
    "        raise ValueError(\"Invalid imputation strategy. Choose 'mean', 'median', 'most_frequent' or 'random'.\")\n",
    "    \n",
    "    # Encode non-numerical columns with integer encoding\n",
    "    X_imputed[categorical_cols] = X_imputed[categorical_cols].apply(LabelEncoder().fit_transform)\n",
    "\n",
    "\n",
    "    # Apply scaling based on the chosen scaling method\n",
    "    if scaling_method == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif scaling_method == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid scaling method. Choose 'minmax' or 'standard'.\")\n",
    "    \n",
    "    # Fit and transform the data\n",
    "    X_scaled = scaler.fit_transform(X_imputed)\n",
    "    X_cleaned = pd.DataFrame.from_records(data=X_scaled, columns=X.columns)\n",
    "    return X_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_test_split, folds):\n",
    "    X_train, X_test, y_train, y_test = train_test_split\n",
    "    param_grid = model[\"params\"]\n",
    "    method = model[\"method\"]\n",
    "    metric = param_grid[\"criterion\"]\n",
    "\n",
    "    # Create a GridSearchCV object with cross-validation\n",
    "    grid_search = GridSearchCV(method, param_grid, cv=folds, n_jobs=-1, scoring=metric, return_train_score=True)\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    return grid_search.best_estimator_, grid_search.best_params_, grid_search.best_score_, grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_Pipeline(json_config):\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    target = train_config[\"target\"]\n",
    "    folds = train_config[\"folds\"]\n",
    "    \n",
    "    df = clean_data(data)\n",
    "    X = df.drop(target, axis=1)\n",
    "    y = df[target]\n",
    "    \n",
    "    data_split = train_test_split(X, y, test_size = train_config[\"test_size\"], shuffle=True, random_state=42)\n",
    "    \n",
    "    stats = []\n",
    "    hyperparams = []\n",
    "    trained_models = []     \n",
    "\n",
    "    for i,model in enumerate(models):               \n",
    "        trained_model, best_params, val_score, cv_results= train_model(model, data_split,folds)\n",
    "        \n",
    "        s = {\"validation_score\": val_score, \"cv_summary\": pd.DataFrame(cv_results)}\n",
    "        stats.append(s)\n",
    "        trained_models.append(trained_model)\n",
    "        hyperparams.append(best_params)\n",
    "    return stats, trained_models, hyperparams\n",
    "\n",
    "def get_best_model(stats, trained_models):\n",
    "    index = np.argmin(stats[1,:])\n",
    "    best_value = np.min(stats[1,:])\n",
    "    model= trained_models[index]\n",
    "    return model,best_value,index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'RF', 'model_type': 'Decision Tree', 'params': {'nModels_search': 5, 'n_estimators': [100, 500], 'max_depth': [1, 20], 'min_samples_split': [2, 8], 'min_samples_leaf': [1, 4], 'max_features': ['auto', 'sqrt'], 'bootstrap': ['True', 'False'], 'criterion': ['gini', 'entropy', 'log_loss']}}\n",
      "{'name': 'DT', 'model_type': 'Decision Tree', 'params': {'max_depth': [1], 'min_samples_split': [2], 'min_samples_leaf': [1], 'max_features': 'auto', 'max_leaf_nodes': [23], 'min_weight_fraction_leaf': [0.0], 'criterion': 'gini', 'splitter': 'best'}}\n",
      "{'is_regression': False, 'CV': False, 'metric': None}\n"
     ]
    }
   ],
   "source": [
    "with open(\"configuration_classification.json\") as json_data:\n",
    "    data = json.load(json_data)\n",
    "print(data[\"Runs\"])\n",
    "print(data[\"Models\"])\n",
    "print(data[\"Training\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_name, folder_name='saved_models'):\n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    # Define the file path\n",
    "    file_path = os.path.join(folder_name, model_name + '.pkl')\n",
    "\n",
    "    # Save the model using joblib\n",
    "    joblib.dump(model, file_path)\n",
    "    print(f\"Model saved at: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_logreg = {\n",
    "    'penalty': ['l1', 'l2'],    # Regularization type\n",
    "    'C': [0.1, 1, 10],          # Inverse of regularization strength\n",
    "    'solver': ['liblinear'],    # Optimization algorithm\n",
    "    'l1_ratio': [0.5, 0.75, 1]          # For elasticnet, mix of L1 and L2 regularization\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],           # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20],             # Maximum depth of each tree\n",
    "    'min_samples_split': [2, 5],                 # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': [1, 2],                     # Whether bootstrap samples are used when building trees\n",
    "    'criterion': ['gini', 'entropy']     # Function to measure the quality of a split\n",
    "}\n",
    "\n",
    "param_grid_ridge = {\n",
    "    'alpha': [0.1, 1, 10],   # Regularization strength\n",
    "    'solver': ['auto', 'svd', 'cholesky'],  # Solver for optimization\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "\n",
    "ridge = {\"method\": Ridge(), \"params\": param_grid_ridge, \"metric\": \"mean_squared_error\"}\n",
    "rf = {\"method\": RandomForestClassifier(), \"params\": param_grid_rf, \"metric\": \"accuracy\"}\n",
    "logreg = {\"method\": LogisticRegression(), \"params\": param_grid_logreg, \"metric\": \"accuracy\"}\n",
    "\n",
    "train_settings = {\"folds\": 5, \"target\": \"age\", \"test_size\": 0.2}\n",
    "\n",
    "stats, trained_models,hyperparams = ML_Pipeline(df, [ridge], train_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  param_alpha  \\\n",
      "0        0.066471      0.029572         0.004461        0.000551          0.1   \n",
      "1        0.992363      0.492570         0.005382        0.001542          0.1   \n",
      "2        0.010878      0.002028         0.006450        0.004625          0.1   \n",
      "3        0.010370      0.002298         0.004656        0.000724          0.1   \n",
      "4        0.015847      0.002687         0.005822        0.001412          0.1   \n",
      "5        0.011055      0.003327         0.004788        0.001251          0.1   \n",
      "6        0.019468      0.013482         0.006193        0.003954          1.0   \n",
      "7        0.018737      0.003918         0.007271        0.004548          1.0   \n",
      "8        0.018134      0.006563         0.011436        0.006925          1.0   \n",
      "9        0.009738      0.002305         0.005138        0.001349          1.0   \n",
      "10       0.016764      0.006927         0.005335        0.001479          1.0   \n",
      "11       0.009385      0.002048         0.007236        0.002698          1.0   \n",
      "12       0.008536      0.001291         0.006796        0.004775         10.0   \n",
      "13       0.024228      0.008834         0.004469        0.001008         10.0   \n",
      "14       0.011183      0.001934         0.004447        0.001352         10.0   \n",
      "15       0.008613      0.000941         0.004316        0.001577         10.0   \n",
      "16       0.015242      0.002763         0.004242        0.001316         10.0   \n",
      "17       0.009990      0.000773         0.003728        0.000799         10.0   \n",
      "\n",
      "    param_fit_intercept param_solver  \\\n",
      "0                  True         auto   \n",
      "1                  True          svd   \n",
      "2                  True     cholesky   \n",
      "3                 False         auto   \n",
      "4                 False          svd   \n",
      "5                 False     cholesky   \n",
      "6                  True         auto   \n",
      "7                  True          svd   \n",
      "8                  True     cholesky   \n",
      "9                 False         auto   \n",
      "10                False          svd   \n",
      "11                False     cholesky   \n",
      "12                 True         auto   \n",
      "13                 True          svd   \n",
      "14                 True     cholesky   \n",
      "15                False         auto   \n",
      "16                False          svd   \n",
      "17                False     cholesky   \n",
      "\n",
      "                                               params  split0_test_score  \\\n",
      "0   {'alpha': 0.1, 'fit_intercept': True, 'solver'...          -0.026710   \n",
      "1   {'alpha': 0.1, 'fit_intercept': True, 'solver'...          -0.026710   \n",
      "2   {'alpha': 0.1, 'fit_intercept': True, 'solver'...          -0.026710   \n",
      "3   {'alpha': 0.1, 'fit_intercept': False, 'solver...          -0.029184   \n",
      "4   {'alpha': 0.1, 'fit_intercept': False, 'solver...          -0.029184   \n",
      "5   {'alpha': 0.1, 'fit_intercept': False, 'solver...          -0.029184   \n",
      "6   {'alpha': 1, 'fit_intercept': True, 'solver': ...          -0.026709   \n",
      "7   {'alpha': 1, 'fit_intercept': True, 'solver': ...          -0.026709   \n",
      "8   {'alpha': 1, 'fit_intercept': True, 'solver': ...          -0.026709   \n",
      "9   {'alpha': 1, 'fit_intercept': False, 'solver':...          -0.029182   \n",
      "10  {'alpha': 1, 'fit_intercept': False, 'solver':...          -0.029182   \n",
      "11  {'alpha': 1, 'fit_intercept': False, 'solver':...          -0.029182   \n",
      "12  {'alpha': 10, 'fit_intercept': True, 'solver':...          -0.026711   \n",
      "13  {'alpha': 10, 'fit_intercept': True, 'solver':...          -0.026711   \n",
      "14  {'alpha': 10, 'fit_intercept': True, 'solver':...          -0.026711   \n",
      "15  {'alpha': 10, 'fit_intercept': False, 'solver'...          -0.029182   \n",
      "16  {'alpha': 10, 'fit_intercept': False, 'solver'...          -0.029182   \n",
      "17  {'alpha': 10, 'fit_intercept': False, 'solver'...          -0.029182   \n",
      "\n",
      "    split1_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
      "0           -0.029629  ...        -0.027809        0.001077                4   \n",
      "1           -0.029629  ...        -0.027809        0.001077                4   \n",
      "2           -0.029629  ...        -0.027809        0.001077                4   \n",
      "3           -0.032101  ...        -0.030045        0.001183               10   \n",
      "4           -0.032101  ...        -0.030045        0.001183               10   \n",
      "5           -0.032101  ...        -0.030045        0.001183               10   \n",
      "6           -0.029627  ...        -0.027809        0.001075                2   \n",
      "7           -0.029627  ...        -0.027809        0.001075                1   \n",
      "8           -0.029627  ...        -0.027809        0.001075                2   \n",
      "9           -0.032101  ...        -0.030045        0.001183               14   \n",
      "10          -0.032101  ...        -0.030045        0.001183               13   \n",
      "11          -0.032101  ...        -0.030045        0.001183               14   \n",
      "12          -0.029615  ...        -0.027815        0.001065                7   \n",
      "13          -0.029615  ...        -0.027815        0.001065                7   \n",
      "14          -0.029615  ...        -0.027815        0.001065                7   \n",
      "15          -0.032114  ...        -0.030062        0.001178               16   \n",
      "16          -0.032114  ...        -0.030062        0.001178               16   \n",
      "17          -0.032114  ...        -0.030062        0.001178               16   \n",
      "\n",
      "    split0_train_score  split1_train_score  split2_train_score  \\\n",
      "0            -0.028008           -0.027278           -0.028000   \n",
      "1            -0.028008           -0.027278           -0.028000   \n",
      "2            -0.028008           -0.027278           -0.028000   \n",
      "3            -0.030189           -0.029456           -0.030327   \n",
      "4            -0.030189           -0.029456           -0.030327   \n",
      "5            -0.030189           -0.029456           -0.030327   \n",
      "6            -0.028008           -0.027278           -0.028000   \n",
      "7            -0.028008           -0.027278           -0.028000   \n",
      "8            -0.028008           -0.027278           -0.028000   \n",
      "9            -0.030189           -0.029456           -0.030327   \n",
      "10           -0.030189           -0.029456           -0.030327   \n",
      "11           -0.030189           -0.029456           -0.030327   \n",
      "12           -0.028016           -0.027286           -0.028007   \n",
      "13           -0.028016           -0.027286           -0.028007   \n",
      "14           -0.028016           -0.027286           -0.028007   \n",
      "15           -0.030209           -0.029475           -0.030346   \n",
      "16           -0.030209           -0.029475           -0.030346   \n",
      "17           -0.030209           -0.029475           -0.030346   \n",
      "\n",
      "    split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
      "0            -0.027748           -0.027635         -0.027734         0.000270  \n",
      "1            -0.027748           -0.027635         -0.027734         0.000270  \n",
      "2            -0.027748           -0.027635         -0.027734         0.000270  \n",
      "3            -0.029895           -0.029997         -0.029973         0.000299  \n",
      "4            -0.029895           -0.029997         -0.029973         0.000299  \n",
      "5            -0.029895           -0.029997         -0.029973         0.000299  \n",
      "6            -0.027748           -0.027635         -0.027734         0.000270  \n",
      "7            -0.027748           -0.027635         -0.027734         0.000270  \n",
      "8            -0.027748           -0.027635         -0.027734         0.000270  \n",
      "9            -0.029896           -0.029997         -0.029973         0.000299  \n",
      "10           -0.029896           -0.029997         -0.029973         0.000299  \n",
      "11           -0.029896           -0.029997         -0.029973         0.000299  \n",
      "12           -0.027756           -0.027642         -0.027741         0.000270  \n",
      "13           -0.027756           -0.027642         -0.027741         0.000270  \n",
      "14           -0.027756           -0.027642         -0.027741         0.000270  \n",
      "15           -0.029915           -0.030016         -0.029992         0.000299  \n",
      "16           -0.029915           -0.030016         -0.029992         0.000299  \n",
      "17           -0.029915           -0.030016         -0.029992         0.000299  \n",
      "\n",
      "[18 rows x 23 columns]\n",
      "[{'validation_score': -0.0278091107081462, 'cv_summary':     mean_fit_time  std_fit_time  mean_score_time  std_score_time  param_alpha  \\\n",
      "0        0.066471      0.029572         0.004461        0.000551          0.1   \n",
      "1        0.992363      0.492570         0.005382        0.001542          0.1   \n",
      "2        0.010878      0.002028         0.006450        0.004625          0.1   \n",
      "3        0.010370      0.002298         0.004656        0.000724          0.1   \n",
      "4        0.015847      0.002687         0.005822        0.001412          0.1   \n",
      "5        0.011055      0.003327         0.004788        0.001251          0.1   \n",
      "6        0.019468      0.013482         0.006193        0.003954          1.0   \n",
      "7        0.018737      0.003918         0.007271        0.004548          1.0   \n",
      "8        0.018134      0.006563         0.011436        0.006925          1.0   \n",
      "9        0.009738      0.002305         0.005138        0.001349          1.0   \n",
      "10       0.016764      0.006927         0.005335        0.001479          1.0   \n",
      "11       0.009385      0.002048         0.007236        0.002698          1.0   \n",
      "12       0.008536      0.001291         0.006796        0.004775         10.0   \n",
      "13       0.024228      0.008834         0.004469        0.001008         10.0   \n",
      "14       0.011183      0.001934         0.004447        0.001352         10.0   \n",
      "15       0.008613      0.000941         0.004316        0.001577         10.0   \n",
      "16       0.015242      0.002763         0.004242        0.001316         10.0   \n",
      "17       0.009990      0.000773         0.003728        0.000799         10.0   \n",
      "\n",
      "    param_fit_intercept param_solver  \\\n",
      "0                  True         auto   \n",
      "1                  True          svd   \n",
      "2                  True     cholesky   \n",
      "3                 False         auto   \n",
      "4                 False          svd   \n",
      "5                 False     cholesky   \n",
      "6                  True         auto   \n",
      "7                  True          svd   \n",
      "8                  True     cholesky   \n",
      "9                 False         auto   \n",
      "10                False          svd   \n",
      "11                False     cholesky   \n",
      "12                 True         auto   \n",
      "13                 True          svd   \n",
      "14                 True     cholesky   \n",
      "15                False         auto   \n",
      "16                False          svd   \n",
      "17                False     cholesky   \n",
      "\n",
      "                                               params  split0_test_score  \\\n",
      "0   {'alpha': 0.1, 'fit_intercept': True, 'solver'...          -0.026710   \n",
      "1   {'alpha': 0.1, 'fit_intercept': True, 'solver'...          -0.026710   \n",
      "2   {'alpha': 0.1, 'fit_intercept': True, 'solver'...          -0.026710   \n",
      "3   {'alpha': 0.1, 'fit_intercept': False, 'solver...          -0.029184   \n",
      "4   {'alpha': 0.1, 'fit_intercept': False, 'solver...          -0.029184   \n",
      "5   {'alpha': 0.1, 'fit_intercept': False, 'solver...          -0.029184   \n",
      "6   {'alpha': 1, 'fit_intercept': True, 'solver': ...          -0.026709   \n",
      "7   {'alpha': 1, 'fit_intercept': True, 'solver': ...          -0.026709   \n",
      "8   {'alpha': 1, 'fit_intercept': True, 'solver': ...          -0.026709   \n",
      "9   {'alpha': 1, 'fit_intercept': False, 'solver':...          -0.029182   \n",
      "10  {'alpha': 1, 'fit_intercept': False, 'solver':...          -0.029182   \n",
      "11  {'alpha': 1, 'fit_intercept': False, 'solver':...          -0.029182   \n",
      "12  {'alpha': 10, 'fit_intercept': True, 'solver':...          -0.026711   \n",
      "13  {'alpha': 10, 'fit_intercept': True, 'solver':...          -0.026711   \n",
      "14  {'alpha': 10, 'fit_intercept': True, 'solver':...          -0.026711   \n",
      "15  {'alpha': 10, 'fit_intercept': False, 'solver'...          -0.029182   \n",
      "16  {'alpha': 10, 'fit_intercept': False, 'solver'...          -0.029182   \n",
      "17  {'alpha': 10, 'fit_intercept': False, 'solver'...          -0.029182   \n",
      "\n",
      "    split1_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
      "0           -0.029629  ...        -0.027809        0.001077                4   \n",
      "1           -0.029629  ...        -0.027809        0.001077                4   \n",
      "2           -0.029629  ...        -0.027809        0.001077                4   \n",
      "3           -0.032101  ...        -0.030045        0.001183               10   \n",
      "4           -0.032101  ...        -0.030045        0.001183               10   \n",
      "5           -0.032101  ...        -0.030045        0.001183               10   \n",
      "6           -0.029627  ...        -0.027809        0.001075                2   \n",
      "7           -0.029627  ...        -0.027809        0.001075                1   \n",
      "8           -0.029627  ...        -0.027809        0.001075                2   \n",
      "9           -0.032101  ...        -0.030045        0.001183               14   \n",
      "10          -0.032101  ...        -0.030045        0.001183               13   \n",
      "11          -0.032101  ...        -0.030045        0.001183               14   \n",
      "12          -0.029615  ...        -0.027815        0.001065                7   \n",
      "13          -0.029615  ...        -0.027815        0.001065                7   \n",
      "14          -0.029615  ...        -0.027815        0.001065                7   \n",
      "15          -0.032114  ...        -0.030062        0.001178               16   \n",
      "16          -0.032114  ...        -0.030062        0.001178               16   \n",
      "17          -0.032114  ...        -0.030062        0.001178               16   \n",
      "\n",
      "    split0_train_score  split1_train_score  split2_train_score  \\\n",
      "0            -0.028008           -0.027278           -0.028000   \n",
      "1            -0.028008           -0.027278           -0.028000   \n",
      "2            -0.028008           -0.027278           -0.028000   \n",
      "3            -0.030189           -0.029456           -0.030327   \n",
      "4            -0.030189           -0.029456           -0.030327   \n",
      "5            -0.030189           -0.029456           -0.030327   \n",
      "6            -0.028008           -0.027278           -0.028000   \n",
      "7            -0.028008           -0.027278           -0.028000   \n",
      "8            -0.028008           -0.027278           -0.028000   \n",
      "9            -0.030189           -0.029456           -0.030327   \n",
      "10           -0.030189           -0.029456           -0.030327   \n",
      "11           -0.030189           -0.029456           -0.030327   \n",
      "12           -0.028016           -0.027286           -0.028007   \n",
      "13           -0.028016           -0.027286           -0.028007   \n",
      "14           -0.028016           -0.027286           -0.028007   \n",
      "15           -0.030209           -0.029475           -0.030346   \n",
      "16           -0.030209           -0.029475           -0.030346   \n",
      "17           -0.030209           -0.029475           -0.030346   \n",
      "\n",
      "    split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
      "0            -0.027748           -0.027635         -0.027734         0.000270  \n",
      "1            -0.027748           -0.027635         -0.027734         0.000270  \n",
      "2            -0.027748           -0.027635         -0.027734         0.000270  \n",
      "3            -0.029895           -0.029997         -0.029973         0.000299  \n",
      "4            -0.029895           -0.029997         -0.029973         0.000299  \n",
      "5            -0.029895           -0.029997         -0.029973         0.000299  \n",
      "6            -0.027748           -0.027635         -0.027734         0.000270  \n",
      "7            -0.027748           -0.027635         -0.027734         0.000270  \n",
      "8            -0.027748           -0.027635         -0.027734         0.000270  \n",
      "9            -0.029896           -0.029997         -0.029973         0.000299  \n",
      "10           -0.029896           -0.029997         -0.029973         0.000299  \n",
      "11           -0.029896           -0.029997         -0.029973         0.000299  \n",
      "12           -0.027756           -0.027642         -0.027741         0.000270  \n",
      "13           -0.027756           -0.027642         -0.027741         0.000270  \n",
      "14           -0.027756           -0.027642         -0.027741         0.000270  \n",
      "15           -0.029915           -0.030016         -0.029992         0.000299  \n",
      "16           -0.029915           -0.030016         -0.029992         0.000299  \n",
      "17           -0.029915           -0.030016         -0.029992         0.000299  \n",
      "\n",
      "[18 rows x 23 columns]}]\n"
     ]
    }
   ],
   "source": [
    "# unpack stats\n",
    "s = pd.DataFrame(stats[0][\"cv_summary\"])\n",
    "print(s)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLE USAGE\n",
    "# train and test split\n",
    "target = \"stroke\"\n",
    "df = clean_data(df)\n",
    "X = df.drop(target, axis=1)\n",
    "y = df[target]\n",
    "split = train_test_split(X, y, test_size = 0.2, shuffle=True, random_state=4)\n",
    "X_train,X_test,y_train,y_test = split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: saved_models\\test.pkl\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_score = trained_models[0].score(X_test, y_test)\n",
    "save_model(trained_models[0], \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.967984318850049\n"
     ]
    }
   ],
   "source": [
    "t = joblib.load(\"model_file_name.pkl\")\n",
    "ts =trained_models[0].score(X_test, y_test)\n",
    "print(ts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
